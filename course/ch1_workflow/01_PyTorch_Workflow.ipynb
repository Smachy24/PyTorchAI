{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PyTorch Workflow",
   "id": "d7adb0f4b3005da0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from numpy import dtype\n",
    "\n",
    "what_were_covering = {\n",
    "    1: \"data (prepare annd load)\",\n",
    "    2: \"build model\",\n",
    "    3: \"fitting the model to data (training)\",\n",
    "    4: \"making predictions and evaluating a model (inference)\",\n",
    "    5: \"saving and loading a model\",\n",
    "    6: \"puttingg it all together\",\n",
    "}\n",
    "what_were_covering"
   ],
   "id": "18c26c416c149477",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn # nn contains all of PyTorch's building blocks for neural networks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check PyTorch vsion\n",
    "torch.__version__\n"
   ],
   "id": "ba8a92471d3723ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Data (preparing and loading)\n",
    "\n",
    "Data can be almost anything... in machine learning.\n",
    "\n",
    "* Excel spreadsheet\n",
    "* Images of any kind\n",
    "* Videos (YouTube has lots of data...)\n",
    "* Audio like songs or podcasts\n",
    "* DNA\n",
    "* Text\n",
    "\n",
    "Machine learning is a game of two parts:\n",
    "1. Get data into a numerical representation.\n",
    "2. Build a model to learn patterns in that numerical representation\n",
    "\n",
    "To showcase this, let's create some *known* data using the linear regression formula.\n",
    "\n",
    "We'll use a linear regression formula to make a straight line with *known* **parameters**."
   ],
   "id": "53401deeeea85f50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create known parameters\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1) # Add extra dimensions (en gros rajouter une dimension / tableau en plus)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ],
   "id": "df6ad123d3a6654a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(X), len(y)",
   "id": "f1490ab0468ab3f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Splitting data into training and test sets (one of the most import concepts in machine learning in general)\n",
    "\n",
    "Let's create a training and test set with our data."
   ],
   "id": "ea70b75d49aafaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a train/test split\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ],
   "id": "9a4f4b0252e940bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How might we better visualize our data ?",
   "id": "86ec1b25211f5d3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    :param train_data:\n",
    "    :param train_labels:\n",
    "    :param test_data:\n",
    "    :param test_labels:\n",
    "    :param predictions:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    # Are the predictions?\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions if they exist\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={'size': 14})"
   ],
   "id": "c97a71b55e695306",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_predictions()",
   "id": "f57c38d9a85f2337",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Build model\n",
    "\n",
    "What our model dors :\n",
    "* Start with random values (weight & bias)\n",
    "* Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight & bias values we used to create the data)\n",
    "\n",
    "How does it do so ?\n",
    "\n",
    "Through two main algorithms:\n",
    "1. Gradient descent - https://www.youtube.com/watch?v=IHZwWFHWa-w\n",
    "2. Backpropagation - https://www.youtube.com/watch?v=Ilg3gGewQ5U"
   ],
   "id": "6428e9bdcc28a8d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "# Create a linear regresion model class\n",
    "class LinearRegressionModel(nn.Module): # -> almost everything in PyTorch inherits from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1,  # -> start with a random weight and try to adjust it to the ideal weight\n",
    "                                                requires_grad=True, # -> can this parameter be updated via gradient descent ?\n",
    "                                                dtype=torch.float)) # -> PyTorch loves the datatype torch.float32\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float))\n",
    "\n",
    "    # Forward method to define the computation in the model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # -> \"x\" is the input data\n",
    "        return self.weights * x + self.bias # this is the linear regression formula\n"
   ],
   "id": "61275097e1d46e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### PyTorch model building essentials\n",
    "\n",
    "* torch.nn - contains all the buildings for computational graphs (a neural network can be considered a computational)\n",
    "* torch.nn.Parameter - what parameters should our model try and learn, often a PyTorch layer from torch.nn will set these for us\n",
    "* torch.nn.Module - The base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
    "* torch.optim - this where the optimizers in PyTorch live, they will help with gradient descent\n",
    "* def forward() - All nn.Module subclasses require you to overwrite forward(), this method defines what happens in the forward computation"
   ],
   "id": "91aa1b3f91a628c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Checking the contents of our PyTorch model\n",
    "\n",
    "Now we've created a model, let's see what's inside...\n",
    "\n",
    "So we can check our model parameters or what's inside our model using `.parameters()`."
   ],
   "id": "ec3712d8b8535b45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a random seeed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module)\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check out the parameters\n",
    "list(model_0.parameters())"
   ],
   "id": "86912a6f938a4d55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List named parameters\n",
    "model_0.state_dict()"
   ],
   "id": "c54d1f856f57bc64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "weight, bias",
   "id": "88272c11552b7f88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Making predictions using `torch.inferennce_mode()`\n",
    "\n",
    "To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`.\n",
    "\n",
    "When we pass data through our model, it's going to run it throught the `forward()`method."
   ],
   "id": "2f481460f13e35e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make predictions with model\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "# You can also do something similar with torch.no_grad(), however, inference_mode() is preferred\n",
    "# with torch.no_grad():\n",
    "#     y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ],
   "id": "4f5930250189ab37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_predictions(predictions=y_preds)",
   "id": "b43da1ed64753b24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Train model\n",
    "\n",
    "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters.\n",
    "\n",
    "Or in other words from a poor representation of the data to a better representation of the data.\n",
    "\n",
    "One way to measure how poor or how wrong your models predictions are is to use a loss function.\n",
    "\n",
    "* Note: Loss function may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
    "\n",
    "Things we need to train :\n",
    "\n",
    "* **Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n",
    "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters (ex: weight and bias in our case) to improve the loss function.\n",
    "    * Inside the optimizer you'll often have to set two parameters\n",
    "        * `params` : the model parameters you'd like to optimize for example `params=model_0.parameters()`\n",
    "        * `lr` (learning rate) : a hyperparameter that defines how big/small the optimizer changes the parameters with each step (a small `lr` results in small changes, a large `lr` results in large changes)\n",
    "\n",
    "\n",
    "And specifically for PyTorch, we need:\n",
    "* A training loop\n",
    "* A testing loop"
   ],
   "id": "8469039d51c47b11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check out our model's parameters (a parameter is a value that the model sets itself)\n",
    "model_0.state_dict()"
   ],
   "id": "2b14e78adfaf222b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup and optimizer (stochastic/random gradient descent)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.0001) # lr = learning rate = possibly the most important hyperparameter you can set"
   ],
   "id": "5fbe3dab0df72dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building a training loop (and a testing loop) in PyTorch\n",
    "\n",
    "A couple of things we need in a training loop:\n",
    "1. Loop through the data and do...\n",
    "2. Forward pass (this involves data moving through our model's `forward()` functions) to make predictions on data - also called forward propagation\n",
    "3. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
    "4. Optimizer zero grad\n",
    "5. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (**backpropagation**)\n",
    "6. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss (**gradient descent**)"
   ],
   "id": "b3c96f2da2d91980"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# An epoch is one loop through the data... (this is a hyperparameter because we've set it ourselves)\n",
    "epochs = 1\n",
    "\n",
    "# Track different values\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 1. Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    # Set the model to training mode\n",
    "    model_0.train() # train mode in PyTorch sets all parameters that require gradients to require gradients\n",
    "\n",
    "    ## 2. Forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 3. Calculate the loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 4. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 5. Perform backpropagation on the loss with respect to the parameters of the model\n",
    "    loss.backward()\n",
    "\n",
    "    # 6. Step the optimizer (perform gradient descent)\n",
    "    optimizer.step() # by default how the optimizer changes will accumulate through the loop so... we have to zero them above in step 4 for the next iteration of the loop\n",
    "\n",
    "    ### Testing\n",
    "    model_0.eval() # turns off different settings in the model not needed for evaluation/testing (dropout/batch norm layers)\n",
    "    with torch.inference_mode(): # turns off gradient tracking & a couple more things behind the scenes\n",
    "        # 2. Do the forward pass\n",
    "        test_pred = model_0(X_test)\n",
    "\n",
    "        # 3. Calculate the loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss.item())\n",
    "        test_loss_values.append(test_loss)\n",
    "        print(f\"Epoch: {epoch} | Loss {loss} | Test loss: {test_loss}\")\n",
    "\n",
    "        # Print out model state_dict()\n",
    "        print(model_0.state_dict())"
   ],
   "id": "20b85d1cbb690aa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, loss_values, label=\"Training Loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test Loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()"
   ],
   "id": "b93f907ebf67edcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds_new = model_0(X_test)"
   ],
   "id": "5662e625d9002d32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_predictions(predictions=y_preds_new)",
   "id": "681ab77ab7d71266",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saving a model in PyTorch\n",
    "\n",
    "There are three main methods you should about for saving and loading models in PyTorch.\n",
    "\n",
    "1. `torch.save()` - allows you save a PyTorch object in Python's pickle format\n",
    "2. `torch.load()`- allows you looad a saved PyTorch object\n",
    "3. `torch.nn.Module.load_state_dict()` - this allows to load a model's saved state dictionnarry"
   ],
   "id": "ecb5d3540145ec59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Saving our PyTorch model\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"../models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create a model save path\n",
    "MODEL_NAME = \"ch1_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state_dict\n",
    "torch.save(model_0.state_dict(), MODEL_SAVE_PATH)"
   ],
   "id": "5d1e7890bde04ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading a PyTorch model\n",
    "\n",
    "Since we saved our model's `state_dict()` rather the entire model, we'll create a new instance of our model class and load the saved `state_dict` into that."
   ],
   "id": "1952c6ec72b96c1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
    "loaded_model_0.load_state_dict(torch.load(MODEL_SAVE_PATH))"
   ],
   "id": "7fbd609b2fd105d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "loaded_model_0.state_dict()",
   "id": "fbeb8c054439f1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make some predictions with our loaded model\n",
    "loaded_model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_model_0(X_test)\n",
    "\n",
    "loaded_model_preds"
   ],
   "id": "3c3eb4c70a24e6e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Make some models preds\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "y_preds"
   ],
   "id": "c3bd3f0f26941208",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare loaded model preds with original model preds\n",
    "y_preds == loaded_model_preds"
   ],
   "id": "d2a921ba0f14ff2c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
